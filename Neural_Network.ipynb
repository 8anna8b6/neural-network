{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okkPd4dvsSAs"
   },
   "source": [
    "### **Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JhclBT4jsJ9s"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork:\n",
    "    \"\"\"\n",
    "    fully-connected feed-forward neural network\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    def __init__(self, layer_sizes=[784, 128, 64, 10], learning_rate=0.3, epochs=15, batch_size=64, decay=0.98, patience=5):\n",
    "        \"\"\"\n",
    "        Initialize the neural network.\n",
    "\n",
    "        Parameters:\n",
    "        - layer_sizes: Number of neurons in each layer\n",
    "        - learning_rate: Initial learning rate for gradient descent\n",
    "        - epochs:Number of epochs to train\n",
    "        - batch_size: Size of mini-batches for training\n",
    "        - decay: Multiplicative decay factor for the learning rate\n",
    "        - patience: Number of epochs with no improvement to wait before early stopping\n",
    "        \"\"\"\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.initial_lr = learning_rate\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.decay = decay\n",
    "        self.patience = patience\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        \"\"\"\n",
    "        Initialize weights using Kaiming initialization and biases with zeros.\n",
    "        \"\"\"\n",
    "        for i in range(len(self.layer_sizes) - 1):\n",
    "            # Kaiming initialization for ReLU activations: w ~ N(0, sqrt(2/layer_sizes))\n",
    "            W = np.random.randn(self.layer_sizes[i], self.layer_sizes[i + 1]) * np.sqrt(2. / self.layer_sizes[i])\n",
    "            # Biases initialized to zero\n",
    "            b = np.zeros((1, self.layer_sizes[i + 1]))\n",
    "            self.weights.append(W)\n",
    "            self.biases.append(b)\n",
    "\n",
    "    def _relu(self, x):\n",
    "        \"\"\"\n",
    "        ReLU activation function.\n",
    "        Returns: max(0, x)\n",
    "        \"\"\"\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def _relu_derivative(self, x):\n",
    "        \"\"\"\n",
    "        Derivative of ReLU.\n",
    "        Returns: 1 where x > 0, else 0\n",
    "        \"\"\"\n",
    "        return (x > 0).astype(float)\n",
    "\n",
    "    def _softmax(self, x):\n",
    "        \"\"\"\n",
    "        Softmax activation function.\n",
    "        \"\"\"\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "    def _forward(self, X):\n",
    "        \"\"\"\n",
    "        Forward pass through the network.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Input data\n",
    "\n",
    "        Returns:\n",
    "        - activations: list of activations per layer\n",
    "        - zs: list of pre-activation values (z) per layer\n",
    "        \"\"\"\n",
    "        activations = [X]\n",
    "        zs = []\n",
    "\n",
    "        for i in range(len(self.weights) - 1):\n",
    "            z = activations[-1] @ self.weights[i] + self.biases[i]\n",
    "            zs.append(z)\n",
    "            a = self._relu(z)\n",
    "            activations.append(a)\n",
    "\n",
    "        # Output layer with Softmax\n",
    "        z = activations[-1] @ self.weights[-1] + self.biases[-1]\n",
    "        zs.append(z)\n",
    "        a = self._softmax(z)  # Apply softmax to final layer\n",
    "        activations.append(a)  # Append correct output activation\n",
    "\n",
    "        return activations, zs\n",
    "\n",
    "    def _backward(self, X, y, activations, zs):\n",
    "        \"\"\"\n",
    "        Backward pass to compute gradients and update weights using backpropagation.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Input batch\n",
    "        - y: True labels\n",
    "        - activations: Activations from forward pass\n",
    "        - zs: Pre-activations from forward pass\n",
    "        \"\"\"\n",
    "        m = X.shape[0]  # batch size\n",
    "        y = y.astype(int)\n",
    "\n",
    "        # convert labels y to one-hot encoding\n",
    "        y_onehot = np.zeros_like(activations[-1])\n",
    "        y_onehot[np.arange(m), y] = 1\n",
    "\n",
    "        # compute delta (error) at output layer\n",
    "        delta = activations[-1] - y_onehot\n",
    "\n",
    "        # gradient for last layer weights and biases\n",
    "        grads_w = [0] * len(self.weights)\n",
    "        grads_b = [0] * len(self.biases)\n",
    "\n",
    "        grads_w[-1] = activations[-2].T @ delta / m\n",
    "        grads_b[-1] = np.sum(delta, axis=0, keepdims=True) / m\n",
    "\n",
    "        # backpropagate through hidden layers using relu derivative\n",
    "        for i in range(len(self.weights) - 2, -1, -1):\n",
    "            delta = (delta @ self.weights[i + 1].T) * self._relu_derivative(zs[i])\n",
    "            grads_w[i] = activations[i].T @ delta / m\n",
    "            grads_b[i] = np.sum(delta, axis=0, keepdims=True) / m\n",
    "\n",
    "        # Update weights and biases here\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] -= self.learning_rate * grads_w[i]\n",
    "            self.biases[i] -= self.learning_rate * grads_b[i]\n",
    "\n",
    "    def fit(self, X_train, y_train, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        Train the neural network with mini-batch gradient descent and optional early stopping.\n",
    "\n",
    "        Parameters:\n",
    "        - X_train: Training features\n",
    "        - y_train: Training labels\n",
    "        - X_val: Validation features (optional)\n",
    "        - y_val: Validation labels (optional)\n",
    "        \"\"\"\n",
    "        best_val_acc = 0\n",
    "        epochs_no_improve = 0\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            # Shuffle training data\n",
    "            indices = np.arange(X_train.shape[0])\n",
    "            np.random.shuffle(indices)\n",
    "            X_shuffled = X_train[indices]\n",
    "            y_shuffled = y_train[indices]\n",
    "\n",
    "            # Mini-batch training\n",
    "            for start in range(0, X_train.shape[0], self.batch_size):\n",
    "                end = start + self.batch_size\n",
    "                X_batch = X_shuffled[start:end]\n",
    "                y_batch = y_shuffled[start:end]\n",
    "\n",
    "                activations, zs = self._forward(X_batch)\n",
    "                self._backward(X_batch, y_batch, activations, zs)\n",
    "\n",
    "            # Decay learning rate\n",
    "            self.learning_rate *= self.decay\n",
    "\n",
    "            # Evaluate on validation set\n",
    "            if X_val is not None and y_val is not None:\n",
    "                val_acc = self.score(X_val, y_val)\n",
    "\n",
    "                if val_acc > best_val_acc:\n",
    "                    best_val_acc = val_acc\n",
    "                    epochs_no_improve = 0\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "\n",
    "                if val_acc >= 0.99:\n",
    "                    print(f\"Early stopping: validation accuracy reached {val_acc:.4f} >= 0.99\")\n",
    "                    break\n",
    "\n",
    "                if epochs_no_improve >= self.patience:\n",
    "                    print(f\"Early stopping: no improvement in validation accuracy for {self.patience} epochs\")\n",
    "                    break\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict class labels for input data.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Input features\n",
    "\n",
    "        Returns:\n",
    "        - predictions: Predicted class\n",
    "        \"\"\"\n",
    "        activations, _ = self._forward(X)\n",
    "        return np.argmax(activations[-1], axis=1)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        Compute accuracy of the model.\n",
    "\n",
    "        Parameters:\n",
    "        - X:  Input features\n",
    "        - y: True labels\n",
    "\n",
    "        Returns:\n",
    "        - accuracy\n",
    "        \"\"\"\n",
    "        predictions = self.predict(X)\n",
    "        return np.mean(predictions == y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xzbBfNcXsxez"
   },
   "source": [
    "### **Main MNIST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XfFSsCWYsYCj",
    "outputId": "af660a19-77a0-474c-a917-f0182ea8e7c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9912\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Load the MNIST datasets\n",
    "    data_train = pd.read_csv(\"MNIST-train.csv\").to_numpy()\n",
    "    data_test = pd.read_csv(\"MNIST-test.csv\").to_numpy()\n",
    "\n",
    "    # Split features and labels\n",
    "    X_train, y_train = data_train[:, :-1], data_train[:, -1]\n",
    "    X_test_full, y_test_full = data_test[:, :-1], data_test[:, -1]\n",
    "\n",
    "    # Normalize pixel values\n",
    "    X_train = X_train / 255.0\n",
    "    X_test_full = X_test_full / 255.0\n",
    "\n",
    "    # Split test set into validation and test sets\n",
    "    split_idx = len(X_test_full) // 2\n",
    "    X_val, y_val = X_test_full[:split_idx], y_test_full[:split_idx]\n",
    "    X_test, y_test = X_test_full[split_idx:], y_test_full[split_idx:]\n",
    "\n",
    "    # Initialize the neural network\n",
    "    nn = NeuralNetwork(layer_sizes=[784, 128, 64, 10],learning_rate=0.4,epochs=15,batch_size=64,decay=0.98,patience=4)\n",
    "\n",
    "    # Train the neural network\n",
    "    nn.fit(X_train, y_train, X_val=X_val, y_val=y_val)\n",
    "\n",
    "    # Evaluate on test data\n",
    "    print('Test accuracy:', nn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "njMdadbPs35L"
   },
   "source": [
    "### **Main Data MB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IsXGzdY_sdnM"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Function to preprocess labels-converts label strings to binary integers\n",
    "def preproess_labels(y):\n",
    "    return np.array([1 if \"Fibro\" in str(s) else 0 for s in y], dtype=int)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Load data\n",
    "    data_train = pd.read_csv(\"MB_data_train.csv\").to_numpy()\n",
    "    #(commented out)\n",
    "    #data_test= pd.read_csv(\"MB_data_test.csv\").to_numpy()\n",
    "\n",
    "    # Extract features and labels\n",
    "    X_train = data_train[:, 1:]  # features\n",
    "    y_train = preproess_labels(data_train[:, 0])  # labels (first column)\n",
    "\n",
    "    #(commented out)\n",
    "    #X_test = data_test[:, 1:]  # features\n",
    "    #y_test = preproess_labels(data_test[:, 0])  # labels (first column)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    #(commented out)\n",
    "    #X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "    # Initialize the neural network\n",
    "    nn = NeuralNetwork(layer_sizes=[X_train.shape[1], 128, 64, 2])\n",
    "    #(commented out)\n",
    "    #nn.fit(X_train, y_train)\n",
    "    # print('Test accuracy:', nn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JuLcMTzysDJM"
   },
   "source": [
    "### **Experiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5IC-fQumrLXG"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graph(param_dict, param_name, x_train, y_train, x_test, y_test, x_val, y_val, folder='graphs'):\n",
    "    \"\"\"\n",
    "    Tests different values of a single parameter and plots accuracy and time in one combined graph.\n",
    "    \"\"\"\n",
    "\n",
    "    accuracies = []\n",
    "    times = []\n",
    "    labels = list(param_dict.keys())\n",
    "\n",
    "    print(f\"\\n\\n--- Testing different values for {param_name} ---\\n\")\n",
    "\n",
    "    for label in labels:\n",
    "        param_value = param_dict[label]\n",
    "        print(f\"\\nTesting {param_name} = {param_value}\")\n",
    "\n",
    "        # Default values\n",
    "        nn_kwargs = {\n",
    "            \"layer_sizes\": [784, 128, 64, 10],\n",
    "            \"learning_rate\": 0.1,\n",
    "            \"epochs\": 15,\n",
    "            \"batch_size\": 64,\n",
    "            \"decay\": 0.98\n",
    "        }\n",
    "\n",
    "        # Override the tested parameter\n",
    "        nn_kwargs[param_name] = param_value\n",
    "\n",
    "        # Create and train the model\n",
    "        nn = NeuralNetwork(**nn_kwargs)\n",
    "\n",
    "        start_time = time.time()\n",
    "        nn.fit(x_train, y_train, X_val=x_val, y_val=y_val)\n",
    "        duration = time.time() - start_time\n",
    "\n",
    "        acc = nn.score(x_test, y_test)\n",
    "        accuracies.append(acc)\n",
    "        times.append(duration)\n",
    "\n",
    "        print(f\"Test Accuracy: {acc:.4f}, Time: {duration:.2f} seconds\")\n",
    "\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Plot combined graph\n",
    "    fig, ax1 = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "    ax1.set_xlabel(param_name)\n",
    "    ax1.set_ylabel('Accuracy', color='crimson')\n",
    "    ax1.plot(labels, accuracies, marker='o', color='crimson', linewidth=2)\n",
    "    ax1.tick_params(axis='y', labelcolor='crimson')\n",
    "    ax1.set_ylim(0.97, 1)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel('Time (seconds)', color='cornflowerblue')\n",
    "    ax2.plot(labels, times, marker='s', color='cornflowerblue', linewidth=2)\n",
    "    ax2.tick_params(axis='y', labelcolor='cornflowerblue')\n",
    "\n",
    "    plt.title(f\"{param_name} vs Accuracy & Time\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(os.path.join(folder, f\"{param_name.replace(' ', '_')}_combined.png\"))\n",
    "    plt.close()\n",
    "\n",
    "def test_and_plot_learning_rates(param_dict, param_name, x_train, y_train, x_test, y_test, x_val, y_val, folder='graphs'):\n",
    "\n",
    "\n",
    "    accuracies = []\n",
    "    times = []\n",
    "    labels = list(param_dict.keys())\n",
    "\n",
    "    print(f\"\\n\\n--- Testing different values for {param_name} ---\\n\")\n",
    "\n",
    "    for label in labels:\n",
    "        param_value = param_dict[label]\n",
    "        print(f\"\\nTesting {param_name} = {param_value}\")\n",
    "\n",
    "\n",
    "\n",
    "        # Create and train the model\n",
    "        nn = NeuralNetwork(layer_sizes=[784, 128, 64, 10], learning_rate=param_value, decay=1)\n",
    "\n",
    "        start_time = time.time()\n",
    "        nn.fit(x_train, y_train, X_val=x_val, y_val=y_val)\n",
    "        duration = time.time() - start_time\n",
    "\n",
    "        acc = nn.score(x_test, y_test)\n",
    "        accuracies.append(acc)\n",
    "        times.append(duration)\n",
    "\n",
    "        print(f\"Test Accuracy: {acc:.4f}, Time: {duration:.2f} seconds\")\n",
    "\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Plot combined graph\n",
    "    fig, ax1 = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "    ax1.set_xlabel(param_name)\n",
    "    ax1.set_ylabel('Accuracy', color='crimson')\n",
    "    ax1.plot(labels, accuracies, marker='o', color='crimson', linewidth=2)\n",
    "    ax1.tick_params(axis='y', labelcolor='crimson')\n",
    "    ax1.set_ylim(0.96 , 1)\n",
    "\n",
    "\n",
    "    plt.title(f\"{param_name} vs Accuracy\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(os.path.join(folder, f\"{param_name.replace(' ', '_')}_combined.png\"))\n",
    "    plt.close()\n",
    "\n",
    "def test_and_plot_layer_configs(layer_configs, X_train, y_train, X_test, y_test, X_val, y_val, folder='graphs'):\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    accuracies = []\n",
    "    times = []\n",
    "    labels = []\n",
    "\n",
    "    for label, config in layer_configs.items():\n",
    "        print(f\"Testing layer_sizes = {config}\")\n",
    "        start = time.time()\n",
    "        nn = NeuralNetwork(layer_sizes=config)\n",
    "        nn.fit(X_train, y_train, X_val=X_val, y_val=y_val)\n",
    "        end = time.time()\n",
    "\n",
    "        acc = nn.score(X_test, y_test)\n",
    "\n",
    "        times.append(end - start)\n",
    "        accuracies.append(acc)\n",
    "        labels.append(label)\n",
    "\n",
    "        print(f\"Test Accuracy: {acc:.4f}, Time: {end - start:.2f} seconds\")\n",
    "\n",
    "    x = range(len(labels))\n",
    "    width = 0.4\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    ax1.bar([i - width / 2 for i in x], accuracies, width=width, color='crimson', label='Accuracy')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.bar([i + width / 2 for i in x], times, width=width, color='cornflowerblue', label='Time')\n",
    "\n",
    "    ax1.set_ylabel('Accuracy', color='crimson')\n",
    "    ax2.set_ylabel('Time (seconds)', color='cornflowerblue')\n",
    "    ax1.set_ylim(0.95, 1.0)\n",
    "    ax1.set_xlabel('Layer Configuration')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(labels, rotation=45)\n",
    "    plt.title('Accuracy vs Time for Different Layer Configurations')\n",
    "\n",
    "    # Legends\n",
    "    l1, lab1 = ax1.get_legend_handles_labels()\n",
    "    l2, lab2 = ax2.get_legend_handles_labels()\n",
    "    plt.legend(l1 + l2, lab1 + lab2, loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(folder, 'layer_config.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hb-fPrR9r0w0"
   },
   "source": [
    "### **TEST LAYERS DEPTH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BbkkMw_urUXc",
    "outputId": "c2e2ef8f-a578-447c-f439-da51e2c16d5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Testing different values for layer_sizes ---\n",
      "\n",
      "\n",
      "Testing layer_sizes = [784, 64, 10]\n",
      "Test Accuracy: 0.9830, Time: 34.25 seconds\n",
      "\n",
      "Testing layer_sizes = [784, 128, 64, 10]\n",
      "Test Accuracy: 0.9858, Time: 61.45 seconds\n",
      "\n",
      "Testing layer_sizes = [784, 256, 128, 64, 10]\n",
      "Early stopping: no improvement in validation accuracy for 5 epochs\n",
      "Test Accuracy: 0.9870, Time: 58.91 seconds\n"
     ]
    }
   ],
   "source": [
    " # ~~~~~~~~~~~~~~~~~~~~~~~TEST LAYERS DEPTH~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "layer_sizes = {\n",
    "      \"1\": [784, 64, 10],\n",
    "      \"2\": [784, 128, 64, 10],\n",
    "      \"3\": [784, 256, 128, 64, 10],\n",
    "\n",
    "}\n",
    "\n",
    "plot_graph(layer_sizes, 'layer_sizes', X_train, y_train, X_test, y_test, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZ6Uv2txrynd"
   },
   "source": [
    "### **TEST LAYERS CONFIGURATIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "XFTRB3UDrXyc",
    "outputId": "7ad5b5c7-b7f4-4921-8499-495b459ece8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing layer_sizes = [784, 64, 10]\n",
      "Early stopping: no improvement in validation accuracy for 5 epochs\n",
      "Test Accuracy: 0.9856, Time: 26.04 seconds\n",
      "Testing layer_sizes = [784, 128, 10]\n",
      "Test Accuracy: 0.9834, Time: 39.73 seconds\n",
      "Testing layer_sizes = [784, 256, 10]\n",
      "Test Accuracy: 0.9894, Time: 63.11 seconds\n",
      "Testing layer_sizes = [784, 512, 256, 10]\n",
      "Early stopping: no improvement in validation accuracy for 5 epochs\n",
      "Test Accuracy: 0.9902, Time: 166.13 seconds\n",
      "Testing layer_sizes = [784, 512, 128, 10]\n",
      "Test Accuracy: 0.9894, Time: 137.23 seconds\n",
      "Testing layer_sizes = [784, 512, 64, 10]\n",
      "Test Accuracy: 0.9908, Time: 123.56 seconds\n",
      "Testing layer_sizes = [784, 256, 128, 10]\n",
      "Test Accuracy: 0.9906, Time: 76.95 seconds\n",
      "Testing layer_sizes = [784, 256, 64, 10]\n",
      "Test Accuracy: 0.9902, Time: 73.66 seconds\n",
      "Testing layer_sizes = [784, 128, 64, 10]\n",
      "Test Accuracy: 0.9894, Time: 40.85 seconds\n",
      "Testing layer_sizes = [784, 256, 128, 64, 10]\n",
      "Test Accuracy: 0.9882, Time: 78.81 seconds\n",
      "Testing layer_sizes = [784, 512, 256, 128, 10]\n",
      "Test Accuracy: 0.9898, Time: 176.05 seconds\n",
      "Testing layer_sizes = [784, 512, 256, 128, 64, 10]\n",
      "Early stopping: no improvement in validation accuracy for 5 epochs\n",
      "Test Accuracy: 0.9904, Time: 148.30 seconds\n"
     ]
    }
   ],
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~TEST LAYERS CONFIGURATIONS~~~~~~~~~~~~~~~~~~~~~~~\n",
    "layer_configs = {\n",
    "      \"[784, 64, 10]\": [784, 64, 10],\n",
    "      \"[784, 128, 10]\": [784, 128, 10],\n",
    "      \"[784, 256, 10]\": [784, 256, 10],\n",
    "      \"[784, 512, 256, 10]\": [784, 512, 256, 10],\n",
    "      \"[784, 512, 128, 10]\": [784, 512, 128, 10],\n",
    "      \"[784, 512, 64, 10]\": [784, 512, 64, 10],\n",
    "      \"[784, 256, 128, 10]\": [784, 256, 128, 10],\n",
    "      \"[784, 256, 64, 10]\": [784, 256, 64, 10],\n",
    "      \"[784, 128, 64, 10]\": [784, 128, 64, 10],\n",
    "      \"[784, 256, 128, 64, 10]\": [784, 256, 128, 64, 10],\n",
    "      \"[784, 512, 256, 128, 10]\": [784, 512, 256, 128, 10],\n",
    "      \"[784, 512, 256, 128, 64, 10]\": [784, 512, 256, 128, 64, 10]\n",
    " }\n",
    "\n",
    "test_and_plot_layer_configs(layer_configs, X_train, y_train, X_test, y_test, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXRDXZmirwhk"
   },
   "source": [
    "### **TEST EPOCHS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "wzo_YYDCraqj",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4e7c610c-3b92-4aae-85bf-a36ce1362ab6"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "--- Testing different values for epochs ---\n",
      "\n",
      "\n",
      "Testing epochs = 5\n",
      "Test Accuracy: 0.9844, Time: 15.16 seconds\n",
      "\n",
      "Testing epochs = 10\n",
      "Test Accuracy: 0.9876, Time: 27.22 seconds\n",
      "\n",
      "Testing epochs = 15\n",
      "Early stopping: no improvement in validation accuracy for 5 epochs\n",
      "Test Accuracy: 0.9860, Time: 43.14 seconds\n",
      "\n",
      "Testing epochs = 20\n",
      "Early stopping: no improvement in validation accuracy for 5 epochs\n",
      "Test Accuracy: 0.9868, Time: 46.97 seconds\n",
      "\n",
      "Testing epochs = 25\n",
      "Early stopping: no improvement in validation accuracy for 5 epochs\n",
      "Test Accuracy: 0.9868, Time: 51.88 seconds\n",
      "\n",
      "Testing epochs = 30\n",
      "Early stopping: no improvement in validation accuracy for 5 epochs\n",
      "Test Accuracy: 0.9864, Time: 64.26 seconds\n"
     ]
    }
   ],
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~TEST EPOCHS~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "epochs = {\n",
    "      \"5 epochs\": 5,\n",
    "      \"10 epochs\": 10,\n",
    "      \"15 epochs\": 15,\n",
    "      \"20 epochs\": 20,\n",
    "      \"25 epochs\": 25,\n",
    "      \"30 epochs\": 30\n",
    "  }\n",
    "plot_graph(epochs, 'epochs', X_train, y_train, X_test, y_test, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HegJA4jbrtuW"
   },
   "source": [
    "### **TEST BATCH SIZE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "9PIyLRSPreKb",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "95fcdd18-b821-43a8-e63d-808ea18bac59"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "--- Testing different values for batch_size ---\n",
      "\n",
      "\n",
      "Testing batch_size = 32\n",
      "Test Accuracy: 0.9886, Time: 55.79 seconds\n",
      "\n",
      "Testing batch_size = 64\n",
      "Test Accuracy: 0.9858, Time: 41.90 seconds\n",
      "\n",
      "Testing batch_size = 128\n",
      "Test Accuracy: 0.9850, Time: 37.15 seconds\n",
      "\n",
      "Testing batch_size = 256\n",
      "Test Accuracy: 0.9818, Time: 32.25 seconds\n"
     ]
    }
   ],
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~TEST BATCH SIZE~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "batch_sizes = {\n",
    "      \"bs=32\": 32,\n",
    "      \"bs=64\": 64,\n",
    "      \"bs=128\": 128,\n",
    "      \"bs=256\": 256\n",
    " }\n",
    "plot_graph(batch_sizes, 'batch_size', X_train, y_train, X_test, y_test, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rZblbd1rrJ8"
   },
   "source": [
    "### **TEST LEARNING RATES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "YWY3Jhw1rhQb",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "70f99b25-9384-4a03-9966-7e249072cae8"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "--- Testing different values for learning_rate ---\n",
      "\n",
      "\n",
      "Testing learning_rate = 0.05\n",
      "Test Accuracy: 0.9842, Time: 44.35 seconds\n",
      "\n",
      "Testing learning_rate = 0.1\n",
      "Test Accuracy: 0.9872, Time: 42.38 seconds\n",
      "\n",
      "Testing learning_rate = 0.15\n",
      "Early stopping: no improvement in validation accuracy for 5 epochs\n",
      "Test Accuracy: 0.9852, Time: 20.60 seconds\n",
      "\n",
      "Testing learning_rate = 0.2\n",
      "Test Accuracy: 0.9872, Time: 42.53 seconds\n",
      "\n",
      "Testing learning_rate = 0.25\n",
      "Test Accuracy: 0.9888, Time: 46.16 seconds\n",
      "\n",
      "Testing learning_rate = 0.3\n",
      "Early stopping: no improvement in validation accuracy for 5 epochs\n",
      "Test Accuracy: 0.9872, Time: 30.32 seconds\n",
      "\n",
      "Testing learning_rate = 0.35\n",
      "Test Accuracy: 0.9910, Time: 41.97 seconds\n",
      "\n",
      "Testing learning_rate = 0.4\n",
      "Test Accuracy: 0.9900, Time: 44.17 seconds\n",
      "\n",
      "Testing learning_rate = 0.45\n",
      "Test Accuracy: 0.9898, Time: 44.86 seconds\n",
      "\n",
      "Testing learning_rate = 0.5\n",
      "Test Accuracy: 0.9882, Time: 41.80 seconds\n",
      "\n",
      "Testing learning_rate = 0.55\n",
      "Test Accuracy: 0.9866, Time: 42.07 seconds\n",
      "\n",
      "Testing learning_rate = 0.6\n",
      "Test Accuracy: 0.9886, Time: 41.41 seconds\n",
      "\n",
      "Testing learning_rate = 0.65\n",
      "Early stopping: no improvement in validation accuracy for 5 epochs\n",
      "Test Accuracy: 0.9842, Time: 32.41 seconds\n",
      "\n",
      "Testing learning_rate = 0.7\n",
      "Early stopping: no improvement in validation accuracy for 5 epochs\n",
      "Test Accuracy: 0.9826, Time: 33.44 seconds\n",
      "\n",
      "Testing learning_rate = 0.75\n",
      "Test Accuracy: 0.9884, Time: 41.09 seconds\n",
      "\n",
      "Testing learning_rate = 0.8\n",
      "Early stopping: no improvement in validation accuracy for 5 epochs\n",
      "Test Accuracy: 0.9862, Time: 42.24 seconds\n",
      "\n",
      "Testing learning_rate = 0.85\n",
      "Test Accuracy: 0.9784, Time: 44.63 seconds\n",
      "\n",
      "Testing learning_rate = 0.9\n",
      "Test Accuracy: 0.9826, Time: 45.18 seconds\n",
      "\n",
      "Testing learning_rate = 0.95\n",
      "Early stopping: no improvement in validation accuracy for 5 epochs\n",
      "Test Accuracy: 0.9742, Time: 32.99 seconds\n"
     ]
    }
   ],
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~TEST LEARNING RATES~~~~~~~~~~~~~~~~~~~~~~~\n",
    "learning_rates = {\n",
    "\n",
    "      \"0.05\": 0.05,\n",
    "      \"0.1\": 0.1,\n",
    "      \"0.15\": 0.15,\n",
    "      \"0.2\": 0.2,\n",
    "      \"0.25\": 0.25,\n",
    "      \"0.3\": 0.3,\n",
    "      \"0.35\": 0.35,\n",
    "      \"0.4\": 0.4,\n",
    "      \"0.45\": 0.45,\n",
    "      \"0.5\": 0.5,\n",
    "      \"0.55\": 0.55,\n",
    "      \"0.6\": 0.6,\n",
    "      \"0.65\": 0.65,\n",
    "      \"0.7\": 0.7,\n",
    "      \"0.75\": 0.75,\n",
    "      \"0.8\": 0.8,\n",
    "      \"0.85\": 0.85,\n",
    "      \"0.9\": 0.9,\n",
    "      \"0.95\": 0.95,\n",
    "\n",
    "\n",
    "  }\n",
    "\n",
    "plot_graph(learning_rates, 'learning_rate', X_train, y_train, X_test, y_test, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wD5if94QroQT"
   },
   "source": [
    "### **TEST DECAY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Jhv5Uhfcrkdr",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "15a07345-9e94-4710-f008-576a2b7d3d98"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "--- Testing different values for decay ---\n",
      "\n",
      "\n",
      "Testing decay = 1.0\n",
      "Test Accuracy: 0.9886, Time: 42.08 seconds\n",
      "\n",
      "Testing decay = 0.99\n",
      "Test Accuracy: 0.9862, Time: 41.31 seconds\n",
      "\n",
      "Testing decay = 0.98\n",
      "Test Accuracy: 0.9870, Time: 44.19 seconds\n",
      "\n",
      "Testing decay = 0.95\n",
      "Test Accuracy: 0.9878, Time: 41.39 seconds\n",
      "\n",
      "Testing decay = 0.9\n",
      "Test Accuracy: 0.9864, Time: 45.08 seconds\n",
      "\n",
      "Testing decay = 0.85\n",
      "Test Accuracy: 0.9854, Time: 42.13 seconds\n",
      "\n",
      "Testing decay = 0.8\n",
      "Test Accuracy: 0.9852, Time: 45.56 seconds\n",
      "\n",
      "Testing decay = 0.7\n",
      "Test Accuracy: 0.9852, Time: 41.55 seconds\n"
     ]
    }
   ],
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~TEST DECAY~~~~~~~~~~~~~~~~~~~~~~~\n",
    "decay_rates = {\n",
    "      \"1.0 (no decay)\": 1.0,\n",
    "      \"0.99\": 0.99,\n",
    "      \"0.98\": 0.98,\n",
    "      \"0.95\": 0.95,\n",
    "      \"0.9\": 0.9,\n",
    "      \"0.85\": 0.85,\n",
    "      \"0.8\": 0.8,\n",
    "      \"0.7\": 0.7,\n",
    "  }\n",
    "plot_graph(decay_rates, 'decay', X_train, y_train, X_test, y_test, X_val, y_val)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
